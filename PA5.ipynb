{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA5 - Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Train Dataset\n",
    "\n",
    "For this step, we will create a Naive Bayes classifier for the \"train\" dataset, provided below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = [\n",
    "    [\"weekday\", \"spring\", \"none\", \"none\", \"on time\"],\n",
    "    [\"weekday\", \"winter\", \"none\", \"slight\", \"on time\"],\n",
    "    [\"weekday\", \"winter\", \"none\", \"slight\", \"on time\"],\n",
    "    [\"weekday\", \"winter\", \"high\", \"heavy\", \"late\"], \n",
    "    [\"saturday\", \"summer\", \"normal\", \"none\", \"on time\"],\n",
    "    [\"weekday\", \"autumn\", \"normal\", \"none\", \"very late\"],\n",
    "    [\"holiday\", \"summer\", \"high\", \"slight\", \"on time\"],\n",
    "    [\"sunday\", \"summer\", \"normal\", \"none\", \"on time\"],\n",
    "    [\"weekday\", \"winter\", \"high\", \"heavy\", \"very late\"],\n",
    "    [\"weekday\", \"summer\", \"none\", \"slight\", \"on time\"],\n",
    "    [\"saturday\", \"spring\", \"high\", \"heavy\", \"cancelled\"],\n",
    "    [\"weekday\", \"summer\", \"high\", \"slight\", \"on time\"],\n",
    "    [\"saturday\", \"winter\", \"normal\", \"none\", \"late\"],\n",
    "    [\"weekday\", \"summer\", \"high\", \"none\", \"on time\"],\n",
    "    [\"weekday\", \"winter\", \"normal\", \"heavy\", \"very late\"],\n",
    "    [\"saturday\", \"autumn\", \"high\", \"slight\", \"on time\"],\n",
    "    [\"weekday\", \"autumn\", \"none\", \"heavy\", \"on time\"],\n",
    "    [\"holiday\", \"spring\", \"normal\", \"slight\", \"on time\"],\n",
    "    [\"weekday\", \"spring\", \"normal\", \"none\", \"on time\"],\n",
    "    [\"weekday\", \"spring\", \"normal\", \"slight\", \"on time\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create this classifier, we first must calculate prior probabilities for each class label.\n",
    "We will do this with the following helper function:\n",
    "\n",
    "* `calculate_priors()`\n",
    "    * **Params**:\n",
    "        * `data` - The dataset to calculate prior probabilities for\n",
    "        * `index` - The index of the classifier value in the dataset\n",
    "        * `classes` - An array of the classes present in the dataset\n",
    "    * **Returns**:\n",
    "        * An array of prior probability values, ordered according to the `classes` param."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_priors(data, index, classes):\n",
    "    counts = {}\n",
    "    total = 0\n",
    "    for label in classes:\n",
    "        counts[label] = 0\n",
    "    for instance in data:\n",
    "        counts[instance[index]] += 1\n",
    "        total += 1\n",
    "    probabilities = []\n",
    "    for label in classes:\n",
    "        probabilities.append(counts[label] / total)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check these values, we will refer to **Figure 3.2** from the Bramer textbook, which claims that the Prior Probabilities for \"on time\", \"late\" \"very late\", and \"cancelled\" should be 0.70, 0.10, 0.15, and 0.05, respectively.\n",
    "\n",
    "We will run our `calculatePriors()` function on these labels and display the values, which should match the given probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7, 0.1, 0.15, 0.05]\n"
     ]
    }
   ],
   "source": [
    "priors = calculate_priors(table, 4, [\"on time\", \"late\", \"very late\", \"cancelled\"])\n",
    "print(priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the values returned from `calculate_priors()` are the same as given in Bramer. Next, we will calculate the posterior probabilities for a given class label. Again, we will create a helper function `calculate_posteriors()` to find these values:\n",
    "\n",
    "* `calculate_posteriors()`\n",
    "    * **Params**:\n",
    "        * `data` - The dataset to calculate probabilities for\n",
    "        * `attributeIndex` - The index of the attribute to calculate conditional probability for\n",
    "        * `attribute` - The value of the index to calculate conditional probability for\n",
    "        * `classIndex` - The index of the class label\n",
    "        * `classLabels` - All classifier labels to calculate conditional probabilities for\n",
    "    * **Returns**:\n",
    "        * A list of posterior probabilities for the given attribute over each class label, ordered with respect to `classLabels()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_posteriors(data, attributeIndex, attribute, classIndex, classLabels):\n",
    "    conditionalCounts = {}\n",
    "    counts = {}\n",
    "    for label in classLabels:\n",
    "        counts[label] = 0\n",
    "        conditionalCounts[label] = 0\n",
    "    for instance in data:\n",
    "        counts[instance[classIndex]] += 1\n",
    "        if instance[attributeIndex] == attribute:\n",
    "            conditionalCounts[instance[classIndex]] += 1\n",
    "    probabilities = []\n",
    "    for label in classLabels:\n",
    "        if counts[label] == 0:\n",
    "            probabilities.append(0)\n",
    "        else:\n",
    "            probabilities.append(conditionalCounts[label] / counts[label])\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we will check our function output against the values provided by Bramer. For the attribute (day = \"weekday\"), we expect the posterior probabilities for class = \"on time\", \"late\", \"very late\", and \"cancelled\" to be 0.64, 0.5, 1, and 0, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6428571428571429, 0.5, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "posteriors = calculate_posteriors(table, 0, \"weekday\", 4, [\"on time\", \"late\", \"very late\", \"cancelled\"])\n",
    "print(posteriors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, our values match up, although Bramer's values round off to 2 decimal places while ours sometimes have more bits of precision.\n",
    "\n",
    "Finally, we can use this to create a Naive Bayes classifier function.\n",
    "\n",
    "* `naive_bayes_classify()`\n",
    "    * **Params**:\n",
    "        * `train` - The data to use as training data\n",
    "        * `classIndex` - The index of the class label\n",
    "        * `classLabels` - A list of all possible class labels\n",
    "        * `test` - The unseen data to classify\n",
    "    * **Returns**:\n",
    "        * A classification for the `test` instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_classify(train, classIndex, classLabels, test):\n",
    "    classProbabilities = []\n",
    "    for val in classLabels:\n",
    "        classProbabilities.append(0)\n",
    "    priors = calculate_priors(train, classIndex, classLabels)\n",
    "    for i in range(len(classProbabilities)):\n",
    "        classProbabilities[i] += priors[i]\n",
    "    for i in range(len(test)):\n",
    "        if i == classIndex:\n",
    "            continue\n",
    "        else:\n",
    "            attribute = test[i]\n",
    "            posteriors = calculate_posteriors(train, i, attribute, classIndex, classLabels)\n",
    "            for i in range(len(posteriors)):\n",
    "                classProbabilities[i] *= posteriors[i]\n",
    "    maxP = 0\n",
    "    index = 0\n",
    "    for i in range(len(classProbabilities)):\n",
    "        if classProbabilities[i] > maxP:\n",
    "            maxP = classProbabilities[i]\n",
    "            index = i\n",
    "    return classLabels[index]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test that our classifier is functioning as intended, we will test it on the trains dataset using the unseen value (\"weekday\", \"winter\", \"high\", \"heavy\", \"???\"). Accordign to Bramer, this should be classified as \"very late\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very late\n"
     ]
    }
   ],
   "source": [
    "label = naive_bayes_classify(table, 4, [\"on time\", \"late\", \"very late\", \"cancelled\"], [\"weekday\", \"winter\", \"high\", \"heavy\", \"???\"])\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, as shown, the `naive_bayes_classify()` function does indeed classify the unseen data correctly. Therefore, we now have a functioning method for using Naive Bayes classification accross a given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - MPG predictor\n",
    "\n",
    "For this step, we will use our Naive Bayes methods on the auo-data dataset. First, we will import the data into an array titled `auto_data`. To generate this data, we will reuse the functions `read_data()`, `create_dataset()`, and `resolve_missing()` from PA4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    f = open(filename, 'r')\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "    return text\n",
    "\n",
    "def create_dataset(data):\n",
    "    data_r = data.splitlines()\n",
    "    dataset = []\n",
    "    for line in data_r:\n",
    "        instance = line.split(',')\n",
    "        dataset.append(instance)\n",
    "    for instance in dataset:\n",
    "        for i in range(10):\n",
    "            try:\n",
    "                instance[i] = float(instance[i])\n",
    "            except:\n",
    "                instance[i] = instance[i]\n",
    "    return dataset\n",
    "\n",
    "def resolve_missing_values(data):\n",
    "    for i in range(10):\n",
    "        if i != 8:\n",
    "            sum_i = 0\n",
    "            count_i = 0\n",
    "            for instance in data:\n",
    "                if instance[i] != \"NA\":\n",
    "                    try:\n",
    "                        sum_i += instance[i]\n",
    "                        count_i += 1\n",
    "                    except:\n",
    "                        print(instance[i])\n",
    "            if count_i == 0:\n",
    "                continue\n",
    "            mean = sum_i / count_i\n",
    "            for instance in data:\n",
    "                if instance[i] == \"NA\":\n",
    "                    instance[i] = mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will use these functions to populate `auto_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_data = create_dataset(read_data(\"auto-data.txt\"))\n",
    "resolve_missing_values(auto_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step only cares about the cyliders, weight, and model year attributes, as well as mpg as a classifier. So, to clean the dataset, we will first go through and restrict it to only these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_auto_data(data):\n",
    "    cleaned_auto_data = []\n",
    "    for instance in data:\n",
    "        cleaned_instance = [instance[1], instance[4], instance[6], instance[0]]\n",
    "        cleaned_auto_data.append(cleaned_instance)\n",
    "    return cleaned_auto_data\n",
    "\n",
    "auto_data = clean_auto_data(auto_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will go through and discretize mpg based on the DOE classification ranking, as well as weight based on the NHTSA vehicle sizes classification. Both tables are given below for reference.\n",
    "\n",
    "| Rating | MPG   |\n",
    "|--------|-----  |\n",
    "|   10   | ≥ 45  |\n",
    "|   9    | 37-44 |\n",
    "|   8    | 31-36 |\n",
    "|   7    | 27-30 |\n",
    "|   6    | 24-26 |\n",
    "|   5    | 20-23 |\n",
    "|   4    | 17-19 |\n",
    "|   3    | 15-16 |\n",
    "|   2    |   14  |\n",
    "|   1    | ≤ 13  |\n",
    "\n",
    "| Ranking |  Weight   |\n",
    "|---------|-----------|\n",
    "|    5    | ≥ 3500    |\n",
    "|    4    | 3000-3499 |\n",
    "|    3    | 2500-2999 |\n",
    "|    2    | 2000-2499 |\n",
    "|    1    | ≤ 1999    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpg_to_DOE(mpg):\n",
    "    if mpg >= 45:\n",
    "        y = 10\n",
    "    elif mpg >= 37:\n",
    "        y = 9\n",
    "    elif mpg >= 31:\n",
    "        y = 8\n",
    "    elif mpg >= 27:\n",
    "        y = 7\n",
    "    elif mpg >= 24:\n",
    "        y = 6\n",
    "    elif mpg >= 20:\n",
    "        y = 5\n",
    "    elif mpg >= 17:\n",
    "        y = 4\n",
    "    elif mpg >= 15:\n",
    "        y = 3\n",
    "    elif mpg >= 14:\n",
    "        y = 2\n",
    "    else:\n",
    "        y = 1\n",
    "    return y\n",
    "\n",
    "def weight_to_NHTSA(weight):\n",
    "    if weight >= 3500:\n",
    "        return 5\n",
    "    elif weight >= 3000:\n",
    "        return 4\n",
    "    elif weight >= 2500:\n",
    "        return 3\n",
    "    elif weight >= 2000:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "    \n",
    "def discretize_auto_data(data):\n",
    "    discrete_data = []\n",
    "    for instance in data:\n",
    "        discrete = [instance[0], weight_to_NHTSA(instance[1]), instance[2], mpg_to_DOE(instance[3])]\n",
    "        discrete_data.append(discrete)\n",
    "    return discrete_data\n",
    "\n",
    "auto_data = discretize_auto_data(auto_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now test our classifier by repeating steps 2-5 from PA4.\n",
    "\n",
    "### Random Instances\n",
    "\n",
    "First, we will test our classifier on a subset of 5 random instances from the dataset. To do so, we must first generate 5 random instances to test. We will reuse `generate_random_instances()` from PA4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import copy\n",
    "\n",
    "def generate_random_instances(data, n):\n",
    "    data_c = copy.deepcopy(data)\n",
    "    test_instances = []\n",
    "    for i in range(n):\n",
    "        index = randint(0, len(data_c)-1)\n",
    "        instance = data_c.pop(index)\n",
    "        test_instances.append(instance)\n",
    "    return test_instances\n",
    "\n",
    "random_test = generate_random_instances(auto_data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will use our `naive_bayes_classify()` function to classify each test instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(train, test):\n",
    "    predictions = []\n",
    "    for instance in test:\n",
    "        predictions.append(naive_bayes_classify(train, 3, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], instance))\n",
    "    return predictions\n",
    "\n",
    "def print_output(test, predictions):\n",
    "    for x in range(len(test)):\n",
    "        print(\"instance: \", test[x][0], \", \", test[x][1], \", \", test[x][2], sep=\"\")\n",
    "        print(\"predicted: \", predictions[x], \", actual: \", test[x][3], sep=\"\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can generate a list of predictions, we will run the classifier and output the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance: 4.0, 2, 77.0\n",
      "predicted: 7, actual: 6\n",
      "\n",
      "instance: 4.0, 3, 76.0\n",
      "predicted: 6, actual: 6\n",
      "\n",
      "instance: 6.0, 4, 74.0\n",
      "predicted: 4, actual: 5\n",
      "\n",
      "instance: 8.0, 4, 78.0\n",
      "predicted: 4, actual: 4\n",
      "\n",
      "instance: 8.0, 5, 73.0\n",
      "predicted: 1, actual: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = generate_predictions(auto_data, random_test)\n",
    "print_output(random_test, predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test / Train sets\n",
    "\n",
    "For this test, we will use stratified cross validation to create a 2:1 train/test set. To generate the train and test sets, we will once again reuse functions from PA4: `create_random_subsample()`, `compute_accuracy()`, and `compute_error()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def create_random_subsample(data, size):\n",
    "    cutoff = int(len(data) * size)\n",
    "    data_c = copy.deepcopy(data)\n",
    "    shuffle(data_c)\n",
    "    train = data_c[:cutoff]\n",
    "    test = data_c[cutoff + 1:]\n",
    "    return test, train\n",
    "\n",
    "def compute_accuracy(predictions, actual):\n",
    "    correct = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == actual[i]:\n",
    "            correct += 1\n",
    "    accuracy = correct / len(predictions)\n",
    "    return accuracy\n",
    "\n",
    "def compute_error(predictions, actual):\n",
    "    incorrect = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] != actual[i]:\n",
    "            incorrect += 1\n",
    "    error = incorrect / len(predictions)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use these functions to generate predictions and print the accuracy and the error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4519230769230769\n",
      "Error Rate:  0.5480769230769231\n"
     ]
    }
   ],
   "source": [
    "test, train = create_random_subsample(auto_data, 2/3)\n",
    "predictions = generate_predictions(train, test)\n",
    "accuracy = compute_accuracy(predictions, [x[3] for x in test])\n",
    "error = compute_error(predictions, [x[3] for x in test])\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Error Rate: \", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified Cross Validation\n",
    "\n",
    "Finally, we will use Stratified 10-Fold Cross Validation to generate random subsamples of test / train data to run our classifier on. \n",
    "\n",
    "We will borrow the function `create_cross_fold()` from PA4 for doing the subsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cross_fold(data, n):\n",
    "    data_r = copy.deepcopy(data)\n",
    "    shuffle(data_r)\n",
    "    size = int(len(data) * 1/n) \n",
    "    start = 0\n",
    "    end = size\n",
    "    folds = []\n",
    "    for i in range(n-1):\n",
    "        folds.append(data[start:end])\n",
    "        start = end + 1\n",
    "        end += size + 1\n",
    "    folds.append(data[start:])\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to run the classifier 10 times, using each subsequent fold as test data and the other 9 folds as training data. For each fold, we will compute an accuracy and error rate, and then display the average at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3471923536439666\n",
      "Error Rate: 0.6528076463560335\n"
     ]
    }
   ],
   "source": [
    "def print_cross_fold_output(data, n):\n",
    "    sum_accuracy = 0\n",
    "    sum_error = 0\n",
    "    folds = create_cross_fold(data, n)\n",
    "    for i in range(n):\n",
    "        test = folds[i]\n",
    "        train = []\n",
    "        for x in range(n):\n",
    "            if x == i:\n",
    "                continue\n",
    "            train += folds[x]\n",
    "        predictions = generate_predictions(train, test)\n",
    "        sum_accuracy += compute_accuracy(predictions, [x[3] for x in test])\n",
    "        sum_error += compute_error(predictions, [x[3] for x in test])\n",
    "    accuracy = sum_accuracy / n\n",
    "    error = sum_error / n\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Error Rate:\", error)\n",
    "    \n",
    "print_cross_fold_output(auto_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
