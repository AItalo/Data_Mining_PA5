{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA5 - Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Train Dataset\n",
    "\n",
    "For this step, we will create a Naive Bayes classifier for the \"train\" dataset, provided below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = [\n",
    "    [\"weekday\", \"spring\", \"none\", \"none\", \"on time\"],\n",
    "    [\"weekday\", \"winter\", \"none\", \"slight\", \"on time\"],\n",
    "    [\"weekday\", \"winter\", \"none\", \"slight\", \"on time\"],\n",
    "    [\"weekday\", \"winter\", \"high\", \"heavy\", \"late\"], \n",
    "    [\"saturday\", \"summer\", \"normal\", \"none\", \"on time\"],\n",
    "    [\"weekday\", \"autumn\", \"normal\", \"none\", \"very late\"],\n",
    "    [\"holiday\", \"summer\", \"high\", \"slight\", \"on time\"],\n",
    "    [\"sunday\", \"summer\", \"normal\", \"none\", \"on time\"],\n",
    "    [\"weekday\", \"winter\", \"high\", \"heavy\", \"very late\"],\n",
    "    [\"weekday\", \"summer\", \"none\", \"slight\", \"on time\"],\n",
    "    [\"saturday\", \"spring\", \"high\", \"heavy\", \"cancelled\"],\n",
    "    [\"weekday\", \"summer\", \"high\", \"slight\", \"on time\"],\n",
    "    [\"saturday\", \"winter\", \"normal\", \"none\", \"late\"],\n",
    "    [\"weekday\", \"summer\", \"high\", \"none\", \"on time\"],\n",
    "    [\"weekday\", \"winter\", \"normal\", \"heavy\", \"very late\"],\n",
    "    [\"saturday\", \"autumn\", \"high\", \"slight\", \"on time\"],\n",
    "    [\"weekday\", \"autumn\", \"none\", \"heavy\", \"on time\"],\n",
    "    [\"holiday\", \"spring\", \"normal\", \"slight\", \"on time\"],\n",
    "    [\"weekday\", \"spring\", \"normal\", \"none\", \"on time\"],\n",
    "    [\"weekday\", \"spring\", \"normal\", \"slight\", \"on time\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create this classifier, we first must calculate prior probabilities for each class label.\n",
    "We will do this with the following helper function:\n",
    "\n",
    "* `calculatePriors()`\n",
    "    * **Params**:\n",
    "        * `data` - The dataset to calculate prior probabilities for\n",
    "        * `index` - The index of the classifier value in the dataset\n",
    "        * `classes` - An array of the classes present in the dataset\n",
    "    * **Returns**:\n",
    "        * An array of prior probability values, ordered according to the `classes` param."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatePriors(data, index, classes):\n",
    "    counts = {}\n",
    "    total = 0\n",
    "    for label in classes:\n",
    "        counts[label] = 0\n",
    "    for instance in data:\n",
    "        counts[instance[index]] += 1\n",
    "        total += 1\n",
    "    probabilities = []\n",
    "    for label in classes:\n",
    "        probabilities.append(counts[label] / total)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check these values, we will refer to **Figure 3.2** from the Bramer textbook, which claims that the Prior Probabilities for \"on time\", \"late\" \"very late\", and \"cancelled\" should be 0.70, 0.10, 0.15, and 0.05, respectively.\n",
    "\n",
    "We will run our `calculatePriors()` function on these labels and display the values, which should match the given probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7, 0.1, 0.15, 0.05]\n"
     ]
    }
   ],
   "source": [
    "priors = calculatePriors(table, 4, [\"on time\", \"late\", \"very late\", \"cancelled\"])\n",
    "print(priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the values returned from `calculatePriors()` are the same as given in Bramer. Next, we will calculate the posterior probabilities for a given class label. Again, we will create a helper function `calculatePosteriors()` to find these values:\n",
    "\n",
    "* `calculatePosteriors()`\n",
    "    * **Params**:\n",
    "        * `data` - The dataset to calculate probabilities for\n",
    "        * `attributeIndex` - The index of the attribute to calculate conditional probability for\n",
    "        * `attribute` - The value of the index to calculate conditional probability for\n",
    "        * `classIndex` - The index of the class label\n",
    "        * `classLabels` - All classifier labels to calculate conditional probabilities for\n",
    "    * **Returns**:\n",
    "        * A list of posterior probabilities for the given attribute over each class label, ordered with respect to `classLabels()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatePosteriors(data, attributeIndex, attribute, classIndex, classLabels):\n",
    "    conditionalCounts = {}\n",
    "    counts = {}\n",
    "    for label in classLabels:\n",
    "        counts[label] = 0\n",
    "        conditionalCounts[label] = 0\n",
    "    for instance in data:\n",
    "        counts[instance[classIndex]] += 1\n",
    "        if instance[attributeIndex] == attribute:\n",
    "            conditionalCounts[instance[classIndex]] += 1\n",
    "    probabilities = []\n",
    "    for label in classLabels:\n",
    "        probabilities.append(conditionalCounts[label] / counts[label])\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we will check our function output against the values provided by Bramer. For the attribute (day = \"weekday\"), we expect the posterior probabilities for class = \"on time\", \"late\", \"very late\", and \"cancelled\" to be 0.64, 0.5, 1, and 0, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6428571428571429, 0.5, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "posteriors = calculatePosteriors(table, 0, \"weekday\", 4, [\"on time\", \"late\", \"very late\", \"cancelled\"])\n",
    "print(posteriors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, our values match up, although Bramer's values round off to 2 decimal places while ours sometimes have more bits of precision.\n",
    "\n",
    "Finally, we can use this to create a Naive Bayes classifier function.\n",
    "\n",
    "* `naiveBayesClassify()`\n",
    "    * **Params**:\n",
    "        * `train` - The data to use as training data\n",
    "        * `classIndex` - The index of the class label\n",
    "        * `classLabels` - A list of all possible class labels\n",
    "        * `test` - The unseen data to classify\n",
    "    * **Returns**:\n",
    "        * A classification for the `test` instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayesClassify(train, classIndex, classLabels, test):\n",
    "    classProbabilities = []\n",
    "    for val in classLabels:\n",
    "        classProbabilities.append(0)\n",
    "    priors = calculatePriors(train, classIndex, classLabels)\n",
    "    for i in range(len(classProbabilities)):\n",
    "        classProbabilities[i] += priors[i]\n",
    "    for i in range(len(test)):\n",
    "        if i == classIndex:\n",
    "            continue\n",
    "        else:\n",
    "            attribute = test[i]\n",
    "            posteriors = calculatePosteriors(train, i, attribute, classIndex, classLabels)\n",
    "            for i in range(len(posteriors)):\n",
    "                classProbabilities[i] *= posteriors[i]\n",
    "    maxP = 0\n",
    "    index = 0\n",
    "    for i in range(len(classProbabilities)):\n",
    "        if classProbabilities[i] > maxP:\n",
    "            maxP = classProbabilities[i]\n",
    "            index = i\n",
    "    return classLabels[index]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test that our classifier is functioning as intended, we will test it on the trains dataset using the unseen value (\"weekday\", \"winter\", \"high\", \"heavy\", \"???\"). Accordign to Bramer, this should be classified as \"very late\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very late\n"
     ]
    }
   ],
   "source": [
    "label = naiveBayesClassify(table, 4, [\"on time\", \"late\", \"very late\", \"cancelled\"], [\"weekday\", \"winter\", \"high\", \"heavy\", \"???\"])\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, as shown, the `naiveBayesClassify()` function does indeed classify the unseen data correctly. Therefore, we now have a functioning method for using Naive Bayes classification accross a given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
