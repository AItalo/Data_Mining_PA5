{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA5 - Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Train Dataset\n",
    "\n",
    "For this step, we will create a Naive Bayes classifier for the \"train\" dataset, provided below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = [\n",
    "    [\"weekday\", \"spring\", \"none\", \"none\", \"on time\"],\n",
    "    [\"weekday\", \"winter\", \"none\", \"slight\", \"on time\"],\n",
    "    [\"weekday\", \"winter\", \"none\", \"slight\", \"on time\"],\n",
    "    [\"weekday\", \"winter\", \"high\", \"heavy\", \"late\"], \n",
    "    [\"saturday\", \"summer\", \"normal\", \"none\", \"on time\"],\n",
    "    [\"weekday\", \"autumn\", \"normal\", \"none\", \"very late\"],\n",
    "    [\"holiday\", \"summer\", \"high\", \"slight\", \"on time\"],\n",
    "    [\"sunday\", \"summer\", \"normal\", \"none\", \"on time\"],\n",
    "    [\"weekday\", \"winter\", \"high\", \"heavy\", \"very late\"],\n",
    "    [\"weekday\", \"summer\", \"none\", \"slight\", \"on time\"],\n",
    "    [\"saturday\", \"spring\", \"high\", \"heavy\", \"cancelled\"],\n",
    "    [\"weekday\", \"summer\", \"high\", \"slight\", \"on time\"],\n",
    "    [\"saturday\", \"winter\", \"normal\", \"none\", \"late\"],\n",
    "    [\"weekday\", \"summer\", \"high\", \"none\", \"on time\"],\n",
    "    [\"weekday\", \"winter\", \"normal\", \"heavy\", \"very late\"],\n",
    "    [\"saturday\", \"autumn\", \"high\", \"slight\", \"on time\"],\n",
    "    [\"weekday\", \"autumn\", \"none\", \"heavy\", \"on time\"],\n",
    "    [\"holiday\", \"spring\", \"normal\", \"slight\", \"on time\"],\n",
    "    [\"weekday\", \"spring\", \"normal\", \"none\", \"on time\"],\n",
    "    [\"weekday\", \"spring\", \"normal\", \"slight\", \"on time\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create this classifier, we first must calculate prior probabilities for each class label.\n",
    "We will do this with the following helper function:\n",
    "\n",
    "* `calculate_priors()`\n",
    "    * **Params**:\n",
    "        * `data` - The dataset to calculate prior probabilities for\n",
    "        * `index` - The index of the classifier value in the dataset\n",
    "        * `classes` - An array of the classes present in the dataset\n",
    "    * **Returns**:\n",
    "        * An array of prior probability values, ordered according to the `classes` param."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_priors(data, index, classes):\n",
    "    counts = {}\n",
    "    total = 0\n",
    "    for label in classes:\n",
    "        counts[label] = 0\n",
    "    for instance in data:\n",
    "        counts[instance[index]] += 1\n",
    "        total += 1\n",
    "    probabilities = []\n",
    "    for label in classes:\n",
    "        probabilities.append(counts[label] / total)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check these values, we will refer to **Figure 3.2** from the Bramer textbook, which claims that the Prior Probabilities for \"on time\", \"late\" \"very late\", and \"cancelled\" should be 0.70, 0.10, 0.15, and 0.05, respectively.\n",
    "\n",
    "We will run our `calculatePriors()` function on these labels and display the values, which should match the given probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7, 0.1, 0.15, 0.05]\n"
     ]
    }
   ],
   "source": [
    "priors = calculate_priors(table, 4, [\"on time\", \"late\", \"very late\", \"cancelled\"])\n",
    "print(priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the values returned from `calculate_priors()` are the same as given in Bramer. Next, we will calculate the posterior probabilities for a given class label. Again, we will create a helper function `calculate_posteriors()` to find these values:\n",
    "\n",
    "* `calculate_posteriors()`\n",
    "    * **Params**:\n",
    "        * `data` - The dataset to calculate probabilities for\n",
    "        * `attributeIndex` - The index of the attribute to calculate conditional probability for\n",
    "        * `attribute` - The value of the index to calculate conditional probability for\n",
    "        * `classIndex` - The index of the class label\n",
    "        * `classLabels` - All classifier labels to calculate conditional probabilities for\n",
    "    * **Returns**:\n",
    "        * A list of posterior probabilities for the given attribute over each class label, ordered with respect to `classLabels()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_posteriors(data, attributeIndex, attribute, classIndex, classLabels):\n",
    "    conditionalCounts = {}\n",
    "    counts = {}\n",
    "    for label in classLabels:\n",
    "        counts[label] = 0\n",
    "        conditionalCounts[label] = 0\n",
    "    for instance in data:\n",
    "        counts[instance[classIndex]] += 1\n",
    "        if instance[attributeIndex] == attribute:\n",
    "            conditionalCounts[instance[classIndex]] += 1\n",
    "    probabilities = []\n",
    "    for label in classLabels:\n",
    "        probabilities.append(conditionalCounts[label] / counts[label])\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we will check our function output against the values provided by Bramer. For the attribute (day = \"weekday\"), we expect the posterior probabilities for class = \"on time\", \"late\", \"very late\", and \"cancelled\" to be 0.64, 0.5, 1, and 0, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6428571428571429, 0.5, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "posteriors = calculate_posteriors(table, 0, \"weekday\", 4, [\"on time\", \"late\", \"very late\", \"cancelled\"])\n",
    "print(posteriors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, our values match up, although Bramer's values round off to 2 decimal places while ours sometimes have more bits of precision.\n",
    "\n",
    "Finally, we can use this to create a Naive Bayes classifier function.\n",
    "\n",
    "* `naive_bayes_classify()`\n",
    "    * **Params**:\n",
    "        * `train` - The data to use as training data\n",
    "        * `classIndex` - The index of the class label\n",
    "        * `classLabels` - A list of all possible class labels\n",
    "        * `test` - The unseen data to classify\n",
    "    * **Returns**:\n",
    "        * A classification for the `test` instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_classify(train, classIndex, classLabels, test):\n",
    "    classProbabilities = []\n",
    "    for val in classLabels:\n",
    "        classProbabilities.append(0)\n",
    "    priors = calculate_priors(train, classIndex, classLabels)\n",
    "    for i in range(len(classProbabilities)):\n",
    "        classProbabilities[i] += priors[i]\n",
    "    for i in range(len(test)):\n",
    "        if i == classIndex:\n",
    "            continue\n",
    "        else:\n",
    "            attribute = test[i]\n",
    "            posteriors = calculate_posteriors(train, i, attribute, classIndex, classLabels)\n",
    "            for i in range(len(posteriors)):\n",
    "                classProbabilities[i] *= posteriors[i]\n",
    "    maxP = 0\n",
    "    index = 0\n",
    "    for i in range(len(classProbabilities)):\n",
    "        if classProbabilities[i] > maxP:\n",
    "            maxP = classProbabilities[i]\n",
    "            index = i\n",
    "    return classLabels[index]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test that our classifier is functioning as intended, we will test it on the trains dataset using the unseen value (\"weekday\", \"winter\", \"high\", \"heavy\", \"???\"). Accordign to Bramer, this should be classified as \"very late\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very late\n"
     ]
    }
   ],
   "source": [
    "label = naive_bayes_classify(table, 4, [\"on time\", \"late\", \"very late\", \"cancelled\"], [\"weekday\", \"winter\", \"high\", \"heavy\", \"???\"])\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, as shown, the `naive_bayes_classify()` function does indeed classify the unseen data correctly. Therefore, we now have a functioning method for using Naive Bayes classification accross a given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - MPG predictor\n",
    "\n",
    "For this step, we will use our Naive Bayes methods on the auo-data dataset. First, we will import the data into an array titled `auto_data`. To generate this data, we will reuse the functions `read_data()`, `create_dataset()`, and `resolve_missing()` from PA4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    f = open(filename, 'r')\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "    return text\n",
    "\n",
    "def create_dataset(data):\n",
    "    data_r = data.splitlines()\n",
    "    dataset = []\n",
    "    for line in data_r:\n",
    "        instance = line.split(',')\n",
    "        dataset.append(instance)\n",
    "    for instance in dataset:\n",
    "        for i in range(10):\n",
    "            try:\n",
    "                instance[i] = float(instance[i])\n",
    "            except:\n",
    "                instance[i] = instance[i]\n",
    "    return dataset\n",
    "\n",
    "def resolve_missing_values(data):\n",
    "    for i in range(10):\n",
    "        if i != 8:\n",
    "            sum_i = 0\n",
    "            count_i = 0\n",
    "            for instance in data:\n",
    "                if instance[i] != \"NA\":\n",
    "                    try:\n",
    "                        sum_i += instance[i]\n",
    "                        count_i += 1\n",
    "                    except:\n",
    "                        print(instance[i])\n",
    "            if count_i == 0:\n",
    "                continue\n",
    "            mean = sum_i / count_i\n",
    "            for instance in data:\n",
    "                if instance[i] == \"NA\":\n",
    "                    instance[i] = mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will use these functions to populate `auto_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_data = create_dataset(read_data(\"auto-data.txt\"))\n",
    "resolve_missing_values(auto_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step only cares about the cyliders, weight, and model year attributes, as well as mpg as a classifier. So, to clean the dataset, we will first go through and restrict it to only these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_auto_data(data):\n",
    "    cleaned_auto_data = []\n",
    "    for instance in data:\n",
    "        cleaned_instance = [instance[1], instance[4], instance[6], instance[0]]\n",
    "        cleaned_auto_data.append(cleaned_instance)\n",
    "    return cleaned_auto_data\n",
    "\n",
    "auto_data = clean_auto_data(auto_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will go through and discretize mpg based on the DOE classification ranking, as well as weight based on the NHTSA vehicle sizes classification. Both tables are given below for reference.\n",
    "\n",
    "| Rating | MPG   |\n",
    "|--------|-----  |\n",
    "|   10   | ≥ 45  |\n",
    "|   9    | 37-44 |\n",
    "|   8    | 31-36 |\n",
    "|   7    | 27-30 |\n",
    "|   6    | 24-26 |\n",
    "|   5    | 20-23 |\n",
    "|   4    | 17-19 |\n",
    "|   3    | 15-16 |\n",
    "|   2    |   14  |\n",
    "|   1    | ≤ 13  |\n",
    "\n",
    "| Ranking |  Weight   |\n",
    "|---------|-----------|\n",
    "|    5    | ≥ 3500    |\n",
    "|    4    | 3000-3499 |\n",
    "|    3    | 2500-2999 |\n",
    "|    2    | 2000-2499 |\n",
    "|    1    | ≤ 1999    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpg_to_DOE(mpg):\n",
    "    if mpg >= 45:\n",
    "        y = 10\n",
    "    elif mpg >= 37:\n",
    "        y = 9\n",
    "    elif mpg >= 31:\n",
    "        y = 8\n",
    "    elif mpg >= 27:\n",
    "        y = 7\n",
    "    elif mpg >= 24:\n",
    "        y = 6\n",
    "    elif mpg >= 20:\n",
    "        y = 5\n",
    "    elif mpg >= 17:\n",
    "        y = 4\n",
    "    elif mpg >= 15:\n",
    "        y = 3\n",
    "    elif mpg >= 14:\n",
    "        y = 2\n",
    "    else:\n",
    "        y = 1\n",
    "    return y\n",
    "\n",
    "def weight_to_NHTSA(weight):\n",
    "    if weight >= 3500:\n",
    "        return 5\n",
    "    elif weight >= 3000:\n",
    "        return 4\n",
    "    elif weight >= 2500:\n",
    "        return 3\n",
    "    elif weight >= 2000:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "    \n",
    "def discretize_auto_data(data):\n",
    "    discrete_data = []\n",
    "    for instance in data:\n",
    "        discrete = [instance[0], weight_to_NHTSA(instance[1]), instance[2], mpg_to_DOE(instance[3])]\n",
    "        discrete_data.append(discrete)\n",
    "    return discrete_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
